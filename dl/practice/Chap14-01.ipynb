{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad9680a",
   "metadata": {},
   "source": [
    "# 모두의 딥러닝 개정 3판 \n",
    "## 14장 모델 성능 향상시키기\n",
    "- validation_split 활용하여 검증셋으로 학습 과정에서 최적의 학습 파라미터를 찾아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f048506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f19c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3      4     5     6       7     8     9    10  11  12\n",
       "0   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1\n",
       "1   7.8  0.88  0.00  2.6  0.098  25.0  67.0  0.9968  3.20  0.68  9.8   5   1\n",
       "2   7.8  0.76  0.04  2.3  0.092  15.0  54.0  0.9970  3.26  0.65  9.8   5   1\n",
       "3  11.2  0.28  0.56  1.9  0.075  17.0  60.0  0.9980  3.16  0.58  9.8   6   1\n",
       "4   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/wine.csv', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9903e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :12]\n",
    "y = df.iloc[:, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e2d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9827804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(30, input_dim=12, activation='relu'))\n",
    "model.add(layers.Dense(12, activation='relu'))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b56706",
   "metadata": {},
   "source": [
    "- 입력층 wieght 12 30   \n",
    "  입력층 bias 1 30   \n",
    "  360+30=390   \n",
    "- hidden층1 wieght 30 12   \n",
    "  hidden층1 bias 1 12  \n",
    "  360+12=372   \n",
    "- hidden층2 wieght 12 8   \n",
    "  hidden층2 bias 1 8   \n",
    "  96+8=104   \n",
    "- 출력층 wieght 8 1    \n",
    "  출력층 bias 1 1   \n",
    "  8+1=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e4afce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                390       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                372       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0efaee0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIT\\miniconda3\\envs\\ml-env\\lib\\site-packages\\keras\\engine\\data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 35ms/step - loss: 0.7042 - accuracy: 0.6017 - val_loss: 0.5375 - val_accuracy: 0.8246\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5203 - accuracy: 0.8006 - val_loss: 0.4980 - val_accuracy: 0.7931\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.7901 - val_loss: 0.4524 - val_accuracy: 0.7954\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.7947 - val_loss: 0.4140 - val_accuracy: 0.8038\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8052 - val_loss: 0.3842 - val_accuracy: 0.8154\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.8191 - val_loss: 0.3480 - val_accuracy: 0.8331\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8383 - val_loss: 0.3133 - val_accuracy: 0.8608\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2988 - accuracy: 0.8725 - val_loss: 0.2774 - val_accuracy: 0.9085\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2678 - accuracy: 0.9148 - val_loss: 0.2550 - val_accuracy: 0.9231\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2480 - accuracy: 0.9274 - val_loss: 0.2428 - val_accuracy: 0.9354\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2361 - accuracy: 0.9325 - val_loss: 0.2296 - val_accuracy: 0.9338\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2255 - accuracy: 0.9325 - val_loss: 0.2176 - val_accuracy: 0.9331\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2104 - accuracy: 0.9307 - val_loss: 0.2116 - val_accuracy: 0.9331\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2021 - accuracy: 0.9323 - val_loss: 0.2036 - val_accuracy: 0.9323\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1971 - accuracy: 0.9333 - val_loss: 0.2025 - val_accuracy: 0.9308\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1929 - accuracy: 0.9338 - val_loss: 0.1999 - val_accuracy: 0.9323\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1905 - accuracy: 0.9333 - val_loss: 0.1980 - val_accuracy: 0.9338\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1877 - accuracy: 0.9356 - val_loss: 0.1966 - val_accuracy: 0.9346\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1851 - accuracy: 0.9356 - val_loss: 0.1965 - val_accuracy: 0.9338\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1825 - accuracy: 0.9358 - val_loss: 0.1938 - val_accuracy: 0.9338\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1800 - accuracy: 0.9366 - val_loss: 0.1914 - val_accuracy: 0.9315\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1777 - accuracy: 0.9364 - val_loss: 0.1885 - val_accuracy: 0.9331\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1766 - accuracy: 0.9387 - val_loss: 0.1907 - val_accuracy: 0.9377\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1730 - accuracy: 0.9369 - val_loss: 0.1874 - val_accuracy: 0.9362\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1690 - accuracy: 0.9379 - val_loss: 0.1838 - val_accuracy: 0.9354\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1655 - accuracy: 0.9384 - val_loss: 0.1823 - val_accuracy: 0.9385\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1632 - accuracy: 0.9405 - val_loss: 0.1810 - val_accuracy: 0.9385\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1630 - accuracy: 0.9412 - val_loss: 0.1819 - val_accuracy: 0.9377\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1612 - accuracy: 0.9425 - val_loss: 0.1757 - val_accuracy: 0.9392\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1597 - accuracy: 0.9420 - val_loss: 0.1757 - val_accuracy: 0.9392\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1543 - accuracy: 0.9430 - val_loss: 0.1733 - val_accuracy: 0.9392\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1538 - accuracy: 0.9438 - val_loss: 0.1745 - val_accuracy: 0.9385\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1556 - accuracy: 0.9430 - val_loss: 0.1764 - val_accuracy: 0.9408\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1593 - accuracy: 0.9451 - val_loss: 0.1758 - val_accuracy: 0.9431\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1566 - accuracy: 0.9448 - val_loss: 0.1842 - val_accuracy: 0.9369\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1565 - accuracy: 0.9446 - val_loss: 0.1651 - val_accuracy: 0.9400\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1504 - accuracy: 0.9443 - val_loss: 0.1838 - val_accuracy: 0.9362\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1491 - accuracy: 0.9435 - val_loss: 0.1615 - val_accuracy: 0.9408\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1451 - accuracy: 0.9469 - val_loss: 0.1640 - val_accuracy: 0.9408\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1419 - accuracy: 0.9464 - val_loss: 0.1650 - val_accuracy: 0.9423\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1403 - accuracy: 0.9469 - val_loss: 0.1596 - val_accuracy: 0.9408\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1417 - accuracy: 0.9487 - val_loss: 0.1576 - val_accuracy: 0.9408\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1377 - accuracy: 0.9474 - val_loss: 0.1584 - val_accuracy: 0.9438\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1366 - accuracy: 0.9482 - val_loss: 0.1552 - val_accuracy: 0.9415\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1360 - accuracy: 0.9487 - val_loss: 0.1545 - val_accuracy: 0.9431\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1341 - accuracy: 0.9484 - val_loss: 0.1548 - val_accuracy: 0.9454\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1330 - accuracy: 0.9484 - val_loss: 0.1511 - val_accuracy: 0.9423\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1342 - accuracy: 0.9492 - val_loss: 0.1579 - val_accuracy: 0.9423\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1309 - accuracy: 0.9497 - val_loss: 0.1576 - val_accuracy: 0.9469\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1343 - accuracy: 0.9512 - val_loss: 0.1484 - val_accuracy: 0.9454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22d77c48cd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25)\n",
    "# 80% 훈련셋, 20% 테스트셋\n",
    "# 80% 훈련셋의 25% 즉 전체의 20%가 validation 진행\n",
    "# 훈련셋의 손실, 정확도보다 validation의 손실, 정확도가 테스트셋이랑 비슷한게 맞다\n",
    "# 복잡한 데이터는 한 epoch 결과를 얻는데 오래 걸린다.\n",
    "# epoch마다 validation을 걸어놓으면 중간에 validation 보고 중간에 중단 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01fb4f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9515\n",
      "Test Accuracy:  0.9515384435653687\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0130f65",
   "metadata": {},
   "source": [
    "- epoch별로 모델을 저장하고 싶을 때  → Chap14-02"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
